{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a33c5ab1-4c39-490f-ad2b-6041bc5de9cb",
   "metadata": {},
   "source": [
    "# LangChain: Memory\n",
    "\n",
    "## Outline\n",
    "* ConversationBufferMemory\n",
    "* ConversationBufferWindowMemory\n",
    "* ConversationTokenBufferMemory\n",
    "* ConversationSummaryMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "591e5815-5664-4a07-b2f2-efa78c6ac6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv('/Users/simonsicard/Projects/chatgpt_training/.env') # read local .env file\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "openai.organization = os.getenv(\"OPENAI_ORGANISATION\")\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b7391e6-e75f-49fa-bcce-227dfa93c441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "print(os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdd3af62-1eba-4ac3-8cb7-5234768b6046",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c498574f-c75c-41dd-9317-48e656288a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.9)\n",
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb3f3517-9e48-4d05-92f8-0ed7bfd8ba26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi, my name is Simon\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello Simon! How can I assist you today?'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hi, my name is Simon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ef26943-4506-4f1d-9da7-657b2fb1e61a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is Simon\n",
      "AI: Hello Simon! How can I assist you today?\n",
      "Human: What is 1+1?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The sum of 1+1 is 2. Is there anything else you would like to know?'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is 1+1?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3e2e6f8-3f0a-48b5-9362-f84f066f3655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is Simon\n",
      "AI: Hello Simon! How can I assist you today?\n",
      "Human: What is 1+1?\n",
      "AI: The sum of 1+1 is 2. Is there anything else you would like to know?\n",
      "Human: What is my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your name is Simon.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a8f2843-4f26-4e66-8d79-11609024bd99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hi, my name is Simon\n",
      "AI: Hello Simon! How can I assist you today?\n",
      "Human: What is 1+1?\n",
      "AI: The sum of 1+1 is 2. Is there anything else you would like to know?\n",
      "Human: What is my name?\n",
      "AI: Your name is Simon.\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0334b885-df44-4cca-9470-fdb62a2f5c70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Hi, my name is Simon\\nAI: Hello Simon! How can I assist you today?\\nHuman: What is 1+1?\\nAI: The sum of 1+1 is 2. Is there anything else you would like to know?\\nHuman: What is my name?\\nAI: Your name is Simon.'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe7b107a-d61c-4392-9500-e19b5143da42",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41ccb80d-c355-4491-bbbd-117fbaf7962f",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c7470d5c-1faa-49b0-9e59-0273640746e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Hi\"}, \n",
    "                    {\"output\": \"What's up\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f47e848e-ba94-40cf-b564-c2cda0687512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hi\n",
      "AI: What's up\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "29f155ec-4ea2-41a6-bad3-05b07c354b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: Hi\\nAI: What's up\"}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff10416e-47c5-4aa0-a0cc-622df083d3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Not much, just hanging\"}, \n",
    "                    {\"output\": \"Cool\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "254332bc-9207-4d85-89a4-40a515078e16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: Hi\\nAI: What's up\\nHuman: Not much, just hanging\\nAI: Cool\"}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a2c6d7-3ad1-44fc-b980-20d8ea3cdf50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e6089e9-9223-43d4-b472-9bdbf507d2df",
   "metadata": {},
   "source": [
    "## ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "69bd83a6-83a9-4152-831a-0b66e058e2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b2fff13c-cca0-45b4-a033-14e2a2af1394",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferWindowMemory(k=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b86fef10-9317-4d4b-8985-7b0fd273466a",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Hi\"},\n",
    "                    {\"output\": \"What's up\"})\n",
    "memory.save_context({\"input\": \"Not much, just hanging\"},\n",
    "                    {\"output\": \"Cool\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8fd523f0-3d8f-4ef4-9b42-01092a685961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Not much, just hanging\\nAI: Cool'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a6dc9fa3-d087-43de-be80-b6f9e30646e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.0)\n",
    "memory = ConversationBufferWindowMemory(k=1)\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c888aaae-9014-41a0-bb31-d3098a9c07e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Andrew! It's nice to meet you. How can I assist you today?\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hi, my name is Andrew\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "60bdbb43-bab8-4fed-82f6-53c241835a90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1+1 is equal to 2.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is 1+1?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aa456074-208c-4856-ad77-f5a50131b357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but I don't have access to personal information about individuals unless it has been shared with me in the course of our conversation.\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265efa49-14bb-4435-9e6f-89f88c35cebc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3339020e-199d-4e94-9c46-2364b8413b71",
   "metadata": {},
   "source": [
    "## ConversationTokenBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "71750a01-1e9c-4841-b217-4726b85bbaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationTokenBufferMemory\n",
    "from langchain.llms import OpenAI\n",
    "llm = ChatOpenAI(temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7904535d-10e5-4ee4-bdb5-7e3e76db7bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d77089df-3787-4378-b22a-31eb8805e8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=30)\n",
    "memory.save_context({\"input\": \"Your name is Irma, you are capble of predicting omens\"},\n",
    "                    {\"output\": \"Amazing! I am going to ask you a few questions and predict your future\"})\n",
    "memory.save_context({\"input\": \"What do you want to know ?\"},\n",
    "                    {\"output\": \"How do you feel right now ?\"})\n",
    "memory.save_context({\"input\": \"Hi\"}, \n",
    "                    {\"output\": \"Hi, what's your name ? When are you born please ?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bbf68664-8c9f-4951-b6b5-873a23e14713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: Hi\\nAI: Hi, what's your name ? When are you born please ?\"}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6671e5a-fddc-4f75-a492-43f9e081be7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48e2461e-a393-4063-b766-7dcba353da8c",
   "metadata": {},
   "source": [
    "## ConversationSummaryMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e74059ee-856c-4b25-81ca-f01c7ddf0689",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3eeefdef-3301-42db-afee-d3aa74fd0a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a long string\n",
    "schedule = \"There is a meeting at 8am with your product team. \\\n",
    "You will need your powerpoint presentation prepared. \\\n",
    "9am-12pm have time to work on your LangChain \\\n",
    "project which will go quickly because Langchain is such a powerful tool. \\\n",
    "At Noon, lunch at the italian resturant with a customer who is driving \\\n",
    "from over an hour away to meet you to understand the latest in AI. \\\n",
    "Be sure to bring your laptop to show the latest LLM demo.\"\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100)\n",
    "memory.save_context({\"input\": \"Hello\"}, {\"output\": \"What's up\"})\n",
    "memory.save_context({\"input\": \"Not much, just hanging\"},\n",
    "                    {\"output\": \"Cool\"})\n",
    "memory.save_context({\"input\": \"What is on the schedule today?\"}, \n",
    "                    {\"output\": f\"{schedule}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0a3e0cc1-71e6-44e3-8cd6-5163c7a8233c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'System: The human and the AI greet each other. The human asks about the schedule for the day and the AI provides a detailed itinerary, including a meeting with the product team, work on the LangChain project, and a lunch meeting with a customer interested in AI. The AI emphasizes the power of LangChain and suggests bringing a laptop to showcase the latest LLM demo during the lunch meeting.'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a43c8b92-74fa-4699-8bac-1392d2138d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e017cb1d-da2c-4f19-af65-8e5adb428754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"A great demo to show during the lunch meeting would be the latest Language Learning Module (LLM) on the LangChain platform. It's a powerful tool that combines natural language processing and machine learning to help users learn languages more effectively. The demo could showcase features like real-time translation, personalized learning paths, and interactive exercises. It's a perfect opportunity to showcase the capabilities of LangChain and how it can benefit the customer in their language learning journey.\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What would be a good demo to show?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b5a30d3c-9bb2-4b3b-b755-879bcd6e6221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! I am an AI assistant designed to provide information and assist with tasks. How can I help you today?'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hello, who are you ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "461351fb-3db0-4928-91e6-7ddb5f0a5184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"System: The human and the AI greet each other and discuss the schedule for the day. The AI provides a detailed itinerary, including a meeting with the product team, work on the LangChain project, and a lunch meeting with a customer interested in AI. The AI suggests bringing a laptop to showcase the latest LLM demo during the lunch meeting and emphasizes the power of LangChain. The human asks what would be a good demo to show. The AI suggests showcasing the latest Language Learning Module (LLM) on the LangChain platform during the lunch meeting. It combines natural language processing and machine learning to help users learn languages more effectively. The demo could showcase features like real-time translation, personalized learning paths, and interactive exercises, demonstrating the capabilities of LangChain in benefiting the customer's language learning journey.\\nHuman: Hello, who are you ?\\nAI: Hello! I am an AI assistant designed to provide information and assist with tasks. How can I help you today?\"}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75da951c-8ca0-4dcb-9f4f-ea3afe4c3497",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d68304e-bf9a-4f80-9911-32b48f194830",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af254dee-f2ab-4e4c-a783-80acd62975f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e548ca4-d87d-4c36-ad48-bd9089f7f66e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a89d57e-8b32-467a-82d7-987790322f44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ENV",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
